
> *Note pour comprendre comment je prends mes notes :*
> En fait moi de base je prends mes notes de cours via un logiciel qui s'appelle **Obsidian** qui permet de prendre des **notes en markdown** (un peu √©tendu). 
> Comme je trouvais √ßa b√™te de faire doublon entre mes notes d√©j√† en markdown synchronis√©e sur un d√©p√¥t git perso et celui que vous attendez de nous pour le cours, je fais un compromis : 
> - j'ai clon√© mon d√©p√¥t "PPE-2025" dans mon arborescence de fichiers o√π je prends mes notes de cours, comme √ßa je peux ouvrir la note actuelle (journal.md) comme mes autres notes via Obsidian. 
> - Pour m'assurer une bonne int√©gration et une mise en lien entre mes notes perso et celles que vous nous imposez, **je me fais (pour moi) des liens parfois vers les notes que je prends dans mes notes perso**. Dans Obsidian, √ßa prend la forme de *double crochets*. Donc si vous voyez par exemple [[Projet de programmation encadr√©|PPE]] c'est parce que je fais r√©f√©rence √† ma note en markdown pour le cours de PPE.
> - Autres sp√©cificit√©s aux notes telles que je les prends : Obsidian permet quelques options suppl√©mentaires comme les *blocs* (comme le bloc "Attentes" ci-dessous, que vous voyez probablement juste comme un bloc de citation) et les ==surlignage== qui prennent la forme d'un encadrement par des signes √©gal.
> - Globalement je vais souvent des liens vers mes notes perso. Par exemple moi de base si en faisant un exo je vois que telle option est pratique √† utiliser pour telle fonction, je pr√©f√®re aller l'√©crire directement dans la notre d√©di√© √† cette fonction, parce que √ßa me fait une sorte de "wiki perso" et je retrouve bien plus vite l'info le jour o√π je veux r√©utiliser cette fonction. J'avoue je me force un peu √† √©crire dans le journal du coup, et √ßa me fait pas mal de doublons... mais bon ü§∑ c'est int√©ressant aussi de pouvoir retracer au jour le jour.

(note √©crite a posteriori, r√©p√®te probablement des trucs du journal)

# Journal de bord du projet encadr√©

Pour le cours de [[Projet de programmation encadr√©]].

> [!Attentes]
> - Journal de bord individuel.
> - Notes un peu au jour le jour (hebdo ?).
> - Je peux aussi y noter si je d√©couvre des fonctions ou manips sympas, des tests.
> - Notes les arguments pratiques pour les fonctions qu'on apprend √† utiliser.
> - Quelles manoeuvres j'ai fait, qu'est-ce qui s'est bien pass√©, qu'est-ce qui s'est mal pass√© ?

> Le journal de bord vous servira tout au long de cette unit√© d‚Äôenseignement, vous devrez y √©crire r√©guli√®rement pour faire part de votre avancement. Vous devrez y indiquer notamment **les probl√®mes que vous avez rencontr√©s et les solutions que vous avez trouv√©es**. 

[[git-intro-exercices.pdf#page=3&selection=85,0,93,12|git-intro-exercices, page 3]]

### Mes id√©es de r√©alisation / questions 
- markdown ? r√©dig√© sous Obsidian? --> vu que je prends d√©j√† mes notes sous markdown dans Obsidian...
- [x] voir si c'est possible de partager juste une note de mon repo obsidian (la note active)  [completion:: 2025-10-06]
	- je vais plut√¥t cr√©er un nouveau r√©po git dans lequel je mets uniquement les notes de PPE (cours et exos) en guise de journal de bord
- ~~sinon juste je copie colle la note (d√©j√† en markdown) si on est cens√© envoyer ~~


## Wed 24.09.2025 - cours d'intro

Je connais d√©j√† la plupart de ce qu'on apprend (cours avec intro au bash suivi et utilisation pendant mon m√©moire l'ann√©e derni√®re + dans ma vie de tous les jours). Mais comme j'ai tout fait en allemand ou anglais jusqu'ici je suis **contente de l'entendre bien expliqu√© en fran√ßais (ma langue maternelle).** :)
Aussi tr√®s contente parce que j'ai d√©couvert le bash expliqu√© par des allemands ing√©nieur en g√©nie m√©canique, et je trouvais √ßa vachement moins clair et sympa que quand c'est *expliqu√© par des int√©ress√©s de linguistique* (l'√©tant moi-m√™me) parce qu'on a plus une approche linguistique (par ex. description du bash comme "*langue √† verbe initial*").

*Int√©r√™t particulier pour le petit point culture / histoire :)*

Des fois je m'emm√™le un poil entre les chemins absolus / relatifs, en particulier je n'√©tais pas trop s√ªre de la notion de r√©pertoire actuel qu'on peut d√©signer par `./`.
Aussi int√©ressant le point sur la vision de tout comme fichier, et d'une arborescence unique (Linux -/- Windows sur ce point).

Je pense pas beaucoup faire de recherches/tests pour le moment en dehors du cours car je connaissais tout ce qu'on a vu.

En fait moi je prends mes notes dans mon repo Obsidian, il faudrait que je montre aux profs et que je demande comment je peux faire converger mon orga perso et leurs attentes.


---

‚ö´Ô∏è‚ö´Ô∏è‚ö´Ô∏è
Pour la suite j'ai juste pris mes notes de cours dans Obsidian.

[[Cours 1 PPE Unix]]
[[Cours 2 PPE git]]

---

### Exercice 1 : cr√©er une arborescence pour classer les documents
Ici : [[unix.pdf#page=23&selection=0,0,0,8|unix, page 23]]

On a t√©l√©charg√© une archive .zip qu'on a unzip avec `unzip`.

Apr√®s avoir tri√© les images dans `img/`, les documents dans `docs/`, les annotations dans `ann`, et les textes dans `txt`, je recr√©e des sous-dossiers en triant par nom : 
- Pour les textes et annotations, je lis la date indiqu√©e pour mettre dans le dossier correspondant.
- Pour les images, je cherche les expressions dans le nom des fichiers qui me donnent une indication sur le lien (Paris ou Tokyo) avec [[grep]].
```sh
ls | grep Tokyo
```
Qui renvoie : 
```sh
0-Paris,Tokyo2.JPG
0-Tokyo!_film_poster.jpg
100-Tokyo_Reverie.jpg
101-Tokyo_Road_best_of_Bon_Jovi.jpg
102-Tokyo_Sando_logo.png
103-Tokyo_Seikatsusha_Network.png
104-Tokyo_Sports.jpg
105-Tokyo_Sungoliath_logo.jpg
106-Tokyo_Super_Wars_official_poster.jpg
...
```

Et toutes ces lignes, on va les bouger dans le sous-dossier `Tokyo/`.
Mais en fait l√† tout de suite je suis pas encore assez au point sur les [[pipe]] pour les commandes √† plusieurs arguments pour faire √ßa avec `grep` (il faudrait que j'utilise la sortie de grep comme premier argument de `mv` et que je puisse ensuite indiquer le sous-dossier `Toyko/`).
Donc pour le moment on va tout faire avec des [[caract√®res de remplacement]] ! :p

```sh
ls *Tokyo*
```

*Note :* les deux commandes nous donnent bien les m√™mes r√©sultats ici (j'ai v√©rifi√© avec le nombre de r√©sultats `ls | grep Tokyo | wc -l` vs `ls *Tokyo* | wc -l`).

Donc, apr√®s avoir cr√©√© le sous-dossier  `Tokyo/`, j'ai lanc√© :
```sh
mv *Tokyo* Tokyo/
```
- Bon, petit souci annonc√© qui est donc qu'en th√©orie j'essaie aussi de d√©placer l dossier `Tokyo/` dans lui-m√™me (action qui √©choue heureusement). Ce serait peut-√™tre bien que je trouve une *option sur mv* pour mettre une exception (p.ex : pas les dossiers, ou pas un certain fichier). ‚úÖ 2025-11-06
	- √ßa semble se faire de fa√ßon plus complexe que ce que je voudrais (m√™me si ce n'est pas super dur non-plus, j'aurais aim√© une simple option sur la commande `mv`) -> quelques sources : [ici](https://unix.stackexchange.com/questions/147290/move-every-file-that-is-not-a-directory#:~:text=There%20is%20one%20way%20to%20match%20by%20type%3A,mv%20--%20%2A%2F%20%22%24tmp%22%20mv%20--%20%2A%20other_directory%2F), 
	- `find . -type f -exec mv {} /destination_folder/ \;`
	- pour mon cas d'usage, je pense que √ßa suffit largement de laisser le terminal rep√©rer qu'il ne peut pas d√©placer un dossier dans lui-m√™me.

Apr√®s globalement j'ai finalement d√©cid√© de faire un petit script qui permet de re-ranger les fichiers dans les dossiers adapt√©s, avec des [[boucles en bash]].

Wed 15.10.2025
Finalement j'ai refait le tri avec ce petit script. 

```sh
#!/bin/bash
for ANNEE in 2016 2017 2018; do
    
    # premier gros tri par ann√©e
    mkdir $ANNEE
    mv ${ANNEE}* ${ANNEE}/

    # sous tri par mois
    cd $ANNEE
    for month in {01..12}; do
        mkdir $month
        # mv ${dossier}_${month}* $month/
        mv ${ANNEE}_${month}* $month/
    done
    cd ..
done
```

Il faut vraiment faire bien attention aux utilisations de variables dans un nom "compos√©" de chemin. Par exemple, quand je faisais `mv $ANNEE_${month}* $month/` √ßa ne marchait pas : il faut bien mettre les accolades autour de `${ANNEE}`.


---

## Mon 06.10.2025 : Exercice git, manipulation de fichiers, tag

[[git-intro-exercices.pdf]]
Mon 06.10.2025

Cr√©ation d'un repo git dans lequel on mettra le [[journal]]. 
Concr√®tement moi je vais d√©placer mes notes faites dans Obsidian dans un repo public pour les profs. Ou peut-√™tre juste les notes d'exercices/projet ..?

Lien vers mon repo : https://github.com/Tejante132/PPE1-2025.git 

On en copie l'adresse [[SSH]] pour faire le lien entre un dossier local et le d√©p√¥t (repo) GitHub, y publier des modifications de d√©p√¥t via le protocole SSH.
```sh
git clone git@github.com:Tejante132/PPE1-2025.git
```

*Note* : GitHub ne supporte plus de publier les modifications de d√©p√¥t via protocole HTTPS pour des raisons de s√©curit√©. Enfin c'est possible mais il faut se connecter √† chaque fois, alors qu'*en utilisant l'adresse SSH pour cloner le repo, on s'identifie avec notre [[cl√© ssh]].*

Lorsqu'on clone un d√©p√¥t, **un dossier au nom de ce d√©p√¥t est automatiquement cr√©√©** dans le dossier courant (o√π on a effectu√© la commande `git clone`). 

---

On teste l'utilisation du clonage : j'ai cr√©√© et "commit" un fichier markdown appel√© `journal.md` depuis le site internet de GitHub, et maintenant on va voir ce qu'affiche la commande [[git status]] (normalement elle affiche qu'il nous manque un fichier).

```sh
clotilde@clotilde-Aspire:~/Documents/Obsidian Vault/Obsidian-Plurital/S7/PPE1-2025$ git status
On branch main
Your branch is up to date with 'origin/main'.

nothing to commit, working tree clean
```

Alors a priori finalement pour le moment il ne me dit rien, mais c'est logique car je n'ai pas r√©cup√©r√© les informations des derni√®res modifications, donc ma version locale ne sait pas qu'il y a une nouvelle version de la banche main. A ses yeux, on est √† jour...
 
 Je vais tester ce que changent les acctions : `git fetch` (m√©tadonn√©es uniquement), et `git pull` (importe les modifications). 
 
```sh
clotilde@clotilde-Aspire:~/Documents/Obsidian Vault/Obsidian-Plurital/S7/PPE1-2025$ git fetch
remote: Enumerating objects: 4, done.
remote: Counting objects: 100% (4/4), done.
remote: Compressing objects: 100% (2/2), done.
remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)
Unpacking objects: 100% (3/3), 997 bytes | 997.00 KiB/s, done.
From github.com:Tejante132/PPE1-2025
   49cd1db..d70ec29  main       -> origin/main
   
clotilde@clotilde-Aspire:~/Documents/Obsidian Vault/Obsidian-Plurital/S7/PPE1-2025$ git status
On branch main
Your branch is behind 'origin/main' by 1 commit, and can be fast-forwarded.
  (use "git pull" to update your local branch)

nothing to commit, working tree clean
```

Apr√®s avoir utilis√© `git fetch`, l'utilisation de `git status` rep√®re maintenant bien qu'on a du retard sur la derni√®re version de la branche main (sans avoir import√© ces modification). D'o√π le message : "Your branch is behind 'origin/main' by 1 commit".

On r√©cup√®re les derni√®res mises √† jour (le fichier `journal.md`) en utilisant `git pull`.

...

Et l√† je viens de regarder le pdf et de voir que je devais peut-√™tre faire autre chose, mais c'est pas grave.
On teste l'utilisation de `git log`:
```sh
clotilde@clotilde-Aspire:~/Documents/Obsidian Vault/Obsidian-Plurital/S7/PPE1-2025$ git log
commit d70ec29f334a68a369596c6f173a774ffd0cf6d5 (HEAD -> main, origin/main, origin/HEAD)
Author: Clotilde Guyard-Gilles <100777239+Tejante132@users.noreply.github.com>
Date:   Mon Oct 6 16:01:32 2025 +0200

    Create journal.md
    
    Ajout du journal de bord

commit 49cd1db551c50f1d3bdc5d3fb0cf36992516d6cf
Author: Clotilde Guyard-Gilles <100777239+Tejante132@users.noreply.github.com>
Date:   Mon Oct 6 15:47:08 2025 +0200

    Initial commit
```

√áa nous liste les commits qui ont √©t√© faits. Pour le moment on en a tr√®s peu, donc pas trop envahissant, mais s'il y en avait plein et qu'on voulait sortir du journal, on pourrait le quitter en touchant la touche "q" (*quit*).

On fait maintenant des modifs locales au fichier (ce que je fais actuellement ;))) )

Donc en utilisant `git status` on devrait maintenant voir qu'on est en avance par rapport au main:
```sh
On branch main
Your branch is up to date with 'origin/main'.

Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
	modified:   journal.md

no changes added to commit (use "git add" and/or "git commit -a")
```

En fait finalement √ßa nous dit juste qu'on n'est √† jour sur le main, mais qu'on a fait de nouvelles modifications sur `journal.md`. Par contre il nous dit que c'est pas n√©cessaire d'`add` les changements, mais c'est peut-√™tre d√ª √† l'application que j'utilise pour prendre mes notes, sur lesquels j'ex√©cute automatiquement r√©guli√®rement des scripts pour pull, add et push les derni√®res modifications.

Du coup par curiosit√© je regarde ce que √ßa change si je fais `git add .` dans mon d√©p√¥t local puis re `git status`.
Quand je dis `git add .`, rien ne s'affiche --> **parce que je n'ai pas cr√©√© de nouveau fichier ? peut-√™tre que `add` / `rm` c'est uniquement pour les nouveaux fichiers, et les `commit` sont pour les changements??**.--> je pense que le `commit` c'est √† la dois ajouts de fichiers et modifications recens√©es. `add` par contre c'est que pour les nouveaux fichiers.

Maintenant, `git status` donne : 
```sh
On branch main
Your branch is up to date with 'origin/main'.

Changes to be committed:
  (use "git restore --staged <file>..." to unstage)
	modified:   journal.md
```

Donc on va pouvoir les `commit` !

On enl√®ve de la synchro git un potentiel fichier qui nous emb√™te `.DS_STORE` gr√¢ce √† un fichier `.gitignore`. Je le cr√©e depuis mon terminal avec `touch`. Dans le fichier, on note simplement `.DS_STORE`. Je le fais aussi depuis le terminal avec : 
```sh
echo ".DS_STORE" >> .gitignore
```

Note : il faut `commit` normalement avant d'appliquer un **tag** sur un commit.
```sh
clotilde@clotilde-Aspire:~/Documents/Obsidian Vault/Obsidian-Plurital/S7/PPE1-2025$ git commit -m "commit fin exo pour tester le tag"
[main ac78641] commit fin exo pour tester le tag
 2 files changed, 170 insertions(+)
 create mode 100644 .gitignore
```

Et pour finir on cr√©e un tag et on le push (cf [[git tag]], notes de [[Cours 2 PPE git]]) : nom du tag "gitinto" et message "version finie intro git".

```sh
git tag -m "version finie intro git" gitinto
git push origin gitinto
```

Qui nous affiche : 
```sh
Enumerating objects: 7, done.
Counting objects: 100% (7/7), done.
Delta compression using up to 16 threads
Compressing objects: 100% (4/4), done.
Writing objects: 100% (5/5), 4.21 KiB | 4.21 MiB/s, done.
Total 5 (delta 0), reused 0 (delta 0), pack-reused 0
To github.com:Tejante132/PPE1-2025.git
 * [new tag]         gitinto -> gitinto
```

Maintenant on va regarder sur GitHub ce que √ßa a donn√© pour le lien.

**Question : si je veux rajouter des modifications au tag, est-ce que c'est possible ?? pour avoir des versions 1.x par exemple.** 

On va tester voir, mais je pense qu'un tag ne peux √™tre qu'unique, donc par exemple ce serait √† moi de nommer le tag diff√©remment, par exemple avec un nouveau tag qui s'appelle "gitinto.1" (avec un versionnement mineur de la version gitinto).

Effectivement ce n'√©tait pas possible de juste refaire un `git tag -m "bla" gitinto`:
```sh
fatal: tag 'gitinto' already exists
```

Donc √† la place j'ai fait : 
```sh
git tag -m "test de modifications sur un tag deja push" gitinto.1
git push origin gitinto.1
```
En cr√©ant donc un nouveau tag.

La question que je me pose par contre maintenant c'est si je pouvais commit et push directement dans un tag d√©j√† existant, sans r√©utiliser la commande `git tag`.

√áa semble avoir march√© !
```sh
clotilde@clotilde-Aspire:~/Documents/Obsidian Vault/Obsidian-Plurital/S7/PPE1-2025$ git commit -m "encore un test pour modifier un tag"
[main c49d815] encore un test pour modifier un tag
 1 file changed, 16 insertions(+), 1 deletion(-)
clotilde@clotilde-Aspire:~/Documents/Obsidian Vault/Obsidian-Plurital/S7/PPE1-2025$ git push origin gitinto
Everything up-to-date
```

Spoiler non en fait c'est l'ancienne version qui est en ligne.

Mais partie fun : **en fait il faut continuer √† push normal dans le main √† c√¥t√© des tags**, parce que l√† la version du main est √† jour d'il y a 53 minutes alors que mon tag est √† jour d'il y a 12min.

Note : je pense que le but c'√©tait de l'appeler gitintro donc mon dernier sera gitintro ;)

---

## Wed 08.10.2025 - Exos scripts bash
cf [[bash|scripts bash]] (mes notes perso sous Obsidian)

On lit les nouvelles slides de [[unix.pdf#page=26&selection=2,0,2,2|unix, page 26]] sur les lignes de commandes -> scripts.
Introduction aux diff√©rents [[flux d'entr√©e-sorties standard]] et [[redirection vers et depuis des fichiers]].

Mes points de doute : 
- [x] pas 100% s√ªre l√† comme √ßa de comment on utilise `<` (par contre les `>` sont bien clairs)  [completion:: 2025-10-08]
	-> *exemple :* `wc < fic.txt` : on redirige le contenu du fichier `fic.txt` dans le stdin.
- [ ] pour la [[redirection vers et depuis des fichiers]] : v√©rifier si la redirection de la sortie d'erreur se fait avec `&<`, `<&` ou les deux ?
- [x] `wc` : le nom laisse entendre que √ßa compte les mots, mais je crois qu'en r√©alit√© √ßa compte plut√¥t les lignes. Tester avec et sens option `-l`. ‚úÖ 2025-11-06
	- [[wc]] peut compter des mots ou des lignes selon l'option qu'on lui donne (respectivement `-w` et `-l`)

On va fair des manipulation sur les [[fichiers .ann]] utilis√©s √† la s√©ance pr√©c√©dente.
-> Avant √ßa je suis all√©e finir le tri parce que je ne l'avais pas fait, comme je savais d√©j√† faire (d√©j√† fait un peu de bash dans mes √©tudes d'ing√©) et que je ne savais pas qu'on en aurait besoin.....

Wed 15.10.2025
### Ex 1 scripts -exos (cours unix.pdf) 
#### v1 √† c√¥t√© de la plaque
**But**
- √âcrire un script qui compte les entit√©s *pour une ann√©e* un type d‚Äôentit√© donn√©s en argument du programme
	- on va utiliser `grep` et `wc` avec un argument donn√© du style `txt` ou `ann`.
	- je cr√©e aussi une variable avec le type d'entit√©
- √âcrire un second script qui lance le script pr√©c√©dent trois fois, une fois pour chaque ann√©es, en prenant le type d‚Äôentit√© en argument.
	- pour √ßa, on fait une boucle for sur les trois ann√©es.
Dans la boucle, j'utilise : 
```sh
ls -l $ANNEE/* | grep ".${ENTITE}" | wc -l
```

**Mes points de difficult√© :** 
- au d√©but j'ai cr√©√© une variable avec une affectation mal r√©dig√©e, puisque j'ai mis des espaces autour du `=`... attention √† bien coller comme √ßa : `ENTITE=$1`.
- somehow √ßa me compte rien, je r√©-essaie... -> le souci √©tait que j'avais fait `ls -l $ANNEE` puis grep etc, mais la seule chose qui √©tait contenue dans chaque r√©pertoire d'ann√©e √©tait des sous-dossiers par mois. J'ai donc rajouter le `\*` pour regarder plus loin.

R√©sultats : 
```sh
$ ./ex1_scripts.sh ann
On va compter les fichiers ann
Nombre de fichiers .ann en 2016: 
571
Nombre de fichiers .ann en 2017: 
393
Nombre de fichiers .ann en 2018: 
227
```

```sh
$ ./ex1_scripts.sh txt
On va compter les fichiers txt
Nombre de fichiers .txt en 2016: 
571
Nombre de fichiers .txt en 2017: 
393
Nombre de fichiers .txt en 2018: 
227
```

---
#### v2 plus sur le bon chemin
En fait je viens d'apprendre que c'√©tait pas du tout √ßa l'exercice ! oups ;)
Donc je refais, cette fois-ci avec l'objectif de compter √† l'int√©rieur d'un document les [[entit√© nomm√©e]]s :

**But**
- √âcrire un script qui compte les entit√©s *pour une ann√©e* un type d‚Äô[[entit√© nomm√©e]] donn√©s en argument du programme *(ex : Location, Person, Date, Organization)*
	- on va utiliser sur des fichierrs .ann donn√©es `grep` et `wc` avec un argument donn√© du style Date, Person, ...
	- je cr√©e aussi une variable avec le type d'EN donn√© qui sera utilis√© dans grep
- √âcrire un second script qui lance le script pr√©c√©dent trois fois, une fois pour chaque ann√©es, en prenant le type d‚Äôentit√© en argument.
	- pour √ßa, on fait une boucle for sur les trois ann√©es.

J'ai fait comme √ßa : 
```sh
EN=$1 # entit√© nomm√©e
echo "On va compter les ${EN}s"
cd ann # on va l√† o√π sont rang√©es les annotations
for ANNEE in 2016 2017 2018; do
    # compte les EN pour cette ann√©e dans chacun des fichiers
    echo "On compte les ${EN}s en $ANNEE :"
    cat $ANNEE/*/* | grep $EN | wc -l
done
cd ..
```

Que j'ai ex√©cut√© comme √ßa:
```sh
$ bash ../ex1_scripts.sh Location
On va compter les Locations
../ex1_scripts.sh: line 32: cd: ann: No such file or directory
On compte les Locations en 2016 :
3144
On compte les Locations en 2017 :
2466
On compte les Locations en 2018 :
3110
```
--> petit souci : j'ai √©cexut√© le programme d√©j√† dans le dossier ann donc c'√©tait pas la peine de mettre un cd ann dans le programme (ou alors j'aurais d√ª √©crire le *chemin absolu* pour que √ßa marche qu'importe d'o√π on ex√©cute le programme)
--> ou alors encore ! j'aurai pu faire en sorte que le chemin vers le dossier soit un *param√®tre du programme* pour que j'adapte selon d'o√π je lance le programme.

> [!J'ai appris]
> - que √ßa marche de faire `cat *` dans un r√©pertoire pour afficher **toutes les lignes de toues les fichiers** qu'on peut lire dans le r√©pertoire actif (**les unes apr√®s les autres**). Pratique pour grep.
> - que par contre le rayon d'action de ce genre de commandes c'est uniquement le r√©pertoire acutel (*pas sous-dossiers*), mais je peux choisir √† quelle "profondeur" je veux aller en utilisant un nombre correspondant de `/*/`. Par exemple ici on a une structure `ann/ann√©e/mois/fichiers_correspondants.ann`, donc en √©tant dans `ann`, si je voulais afficher les fichiers ann, je devais afficher tous les mois avec une `*` (cf code).


---

### v3 : la fiche d'exos ??
Booon en fait je viens encore de voir qu'il vallait mieux suivre les exos de la fiche d'exos plut√¥t que ceux du cours. cf [[01-scripts-exercices.pdf]].

> J'avoue m'√©nerve un peu parce que j'avais fait les exos donn√©s dans les slides de cours et ils sont l√©g√®rement diff√©rents de ceux dans la fiche de TD mais sont quand-m√™me proches. :(
> Je verrai si j'ai la foi de refaire exactement le TD pendant les vacances, pour le moment je me concentre sur suivre en direct ce qu'on fait maintenant pour pas prendre de retard.

### Ex 2 scripts -exos (cours unix.pdf) 
- [x] cr√©er un script pour √©tablir le classement des lieux les plus cit√©s. ‚úÖ 2025-11-06
- [x] prendre en argument l‚Äôann√©e, le mois et le nombre de lieux √† afficher ‚úÖ 2025-11-06
- [x] accepter * pour l‚Äôann√©e et le mois. ‚úÖ 2025-11-06

Outils √† utiliser : 
- tail ou `head` (s√©lectionner un certain nombre de lieux)
- trier ?? `sort` ?? `uniq` !!!

Pour le moment j'ai √ßa : 

```bash
echo "Nb d'arguments donn√©s : $#"

if [ $# -ne 3 ] # On n'a pas donn√© 3 arguments
then
    echo "Merci de donner 3 arguments svp : ann√©e (2016, 2017, 2018 ou toutes "*"), mois (tous : "*"), nombre de lieux √† afficher (classement des lieux les plus cit√©s)"
    exit
fi

ANNEE=$1
MOIS=$2
NB_LIEUX=$3
EN="Location" # entit√© nomm√©e

echo "On va trier les ${NB_LIEUX} ${EN}s les plus mentionn√©es en ${MOIS} ${ANNEE}."

# Prise en compte de l'ast√©risque
cat ann/${ANNEE}/${MOIS}/* | grep "Location" | ... # √† compl√©ter
```

L√† j'ai juste la liste de tous les lieux. Pour compter le nombre d'apparition de chaque lieu et les trier par nombre d'apparition, je vais investiguer sur les options de `uniq` et `sort`.

`uniq` poss√®de l'option suivante : 
```
  -c, --count           prefix lines by the number of occurrences
```
Ce qui serait niquel pour moi comme premi√®re liste sur laquelle utiliser `sort`.
Par contre avant √ßa il faudrait que je ne garde que la derni√®re colonne (colonne avec nom du lieu).

Je regarde de plus pr√®s le format des annotations. Ligne typique : 
```
T7	Location 195 223	18 e arrondissement de Paris
```
Avec `TXX` (n¬∞ d'annotation) puis **tabulation** puis `<EN_type> XXX XXX` puis **tabulation** puis le nom de l'EN (ce qu'on veut garder).

En cours, on a mentionn√© la commande `cut` qui a cet effet : 

| Commande | Action                                                                        | Exemple                                          |
| :------- | :---------------------------------------------------------------------------- | :----------------------------------------------- |
| `cut`    | Extrait certaines colonnes ou champs d‚Äôun texte (par position ou s√©parateur). | `cut -d',' -f2 data.csv` (extrait la 2·µâ colonne) |
Pour mon cas, le d√©limiteur de colonnes et la tabulation `'\t'`.
Donc je tente :
```bash
cat ann/${ANNEE}/${MOIS}/* | grep "Location" | cut -d$'\t' -f3
```

(j'ai piqu√© l'id√©e du `cut -d$'\t' -f3` [ici](https://unix.stackexchange.com/questions/35369/how-to-define-tab-delimiter-with-cut-in-bash))

Maintenant on y applique `uniq -c` pout compter (`--count`).

```bash
cat ann/${ANNEE}/${MOIS}/* | grep "Location" | cut -d$'\t' -f3 | uniq -c
```

√áa ne marche que mollo mollo... puisque je vois par exemple des doublons de Locations : 
```
  1 Royaume-Uni
  1 Ukraine
  1 Allemagne
  1 Espagne
  1 Italie
  1 France
  1 Royaume-Uni
```
*Extrait du `uniq` : on voit 2 fois Royaume-Uni compt√© "1 fois.*
Pourtant, certaines autre lignes ont bien autre chose que 1 (je ne vois que quelques 2, un 4, un 3).

L√† en faisant √ßa:
```bash
cat ann/${ANNEE}/${MOIS}/* | grep "Location" | cut -d$'\t' -f3 | uniq -c | sort -bgr
```

√áa me trie bien d'abord par nombre d'apparition puis par nom de lieu.
Mais j'ai toujours le souci (maintenant d'autant plus flagrant) des noms pr√©sents plusieurs fois mais compt√©s moins de fois.
Par exemple je fois 7 fois "Burundi" mais compt√© comme "4"...

Si vraiment √ßa ne marche pas, je pourrai lire les valeurs uniques des noms de lieux, et pour chacun chercher le nombre de fois o√π il apparait. Mais √ßa ne me sembl pas tr√®s efficace.

Je me demande s'il y a le souci de retours de ligne, d√ª √©ventuellement √† la concat√©nation de diff√©rents documents.

Recherches sur internet...
Une solution est de **d'abord trier les lignes** avant de les passer dans `uniq`, qui ne compte que les *lignes cons√©cutives qui se r√©p√®tent*.

```bash
cat ann/${ANNEE}/${MOIS}/* | grep "Location" | cut -d$'\t' -f3 | sort | uniq -c -i | sort -bgr
```

Note : l'option `-i` rend insensible √† la casse.

Et maintenant, en appliquant `tail -n ${NB_LIEUX}` √† la fin, on a notre classement ! 

Exemple d'utilisation : 
```bash
$ bash compte_lieux.sh 2018 12 5
Classement des 5 Locations les plus mentionn√©es en 12 2018.
    150 Paris
    103 france
     76 Champs-√âlys√©es
     28 A9
     24 A7
```


---

## Wed 15.10.2025 - Instructions de contr√¥le

Petite update du sccript fait pour le tri pour tester le fait de v√©rifier les arguments. J'ai rajout√© au d√©but (avant d'ex√©cuter le reste du code) : 
```sh
EN=$1 # entit√© nomm√©e

if [ -z  $EN] # aucun argument n'a √©t√© donn√©
then
    echo "donnez un type d'entit√© nomm√©e (ex : Location, Person, Organization) en argument svp"
    exit
else
    echo "On va compter les ${EN}s"
fi
```

Et test√© d'essayer de lancer le script avec et sans EN donn√©e : 
```sh
sh-5.2$ bash ../ex1_scripts.sh 
donnez un type d'entit√© nomm√©e (ex : Location, Person, Organization) en argument svp
sh-5.2$ bash ../ex1_scripts.sh Location
../ex1_scripts.sh: line 30: [: missing `]'
On va compter les Locations
On compte les Locations en 2016 :
3144
On compte les Locations en 2017 :
2466
On compte les Locations en 2018 :
3110
```

Top!

### Description de ce qu'il se passe dans le code donn√© en fin du cours [[unix.pdf]] 

Annotation d'un code :
```sh
#!/usr/bin/bash    # shebang

if [ $# - ne 1 ]    # si le nombre total d'arguments n'est pas 1
then 
	echo " ce programme demande un argument "  # pr√©vient (msg d'erreur)
	exit  # interrompt le programme
fi   # sortie de structure `if`


FICHIER_URLS=$1  # affectation de la valeur donn√©e en argument
OK=0  # cr√©ation de deux variables OK et NOK de valeurs 0
NOK=0 

while read -r LINE ; # je suppose que a veut dire qu'on a de quoi lire  ??? mais c'est qui LINE ici ?
do 
	echo "la ligne : $LINE" 
	if [[ $LINE =‚àº ^https?:// ]]  # on teste avec regex si la ligne correspond √† une adresse web / un site
	then 
		echo " ressemble √† une URL valide " 
		OK = $(expr $OK + 1)  # it√©r√© compte les adresses web valides
	else 
		echo " ne ressemble pas √† une URL valide "
		NOK = $(expr $NOK + 1)  # it√®re le compteur d'URL pas OK
	fi 
done < $FICHIER_URLS # ah ben je crois que je sais : les LINES sont lues dans le fichier donn√© ici √† la boucle while...do...done

echo " $OK URLs et $NOK lignes douteuses "
```


*Ce que fait ce code :* 
- Si le nombre total d'arguments n'est pas 1, pr√©vient qu'il faut un argument et quitte le programme.
- *... (voir commentaires dans le code)*
- $FICHIER_URLS donne le chemin vers le fichier texte (==au while read== )
	- il y a un chevron dans `done < $FICHIER_URLS` 
	- ici le contenu du fichier est "branch√©" sur l'entr√©e standard du done... -> il r√©pond en fait √† tout le bloc `while ... do ... done` 
- `read` -> cf page d'aide pour savoir comment √ßa marche.. ([[read]])

### `read`
La commande `read` en Bash est utilis√©e pour *lire une ligne de texte depuis l'entr√©e standard (par d√©faut)* ou un descripteur de fichier, et **l'assigner √† une ou plusieurs variables**.

Prend en **argument un nom de variable** et stocke sur l'entr√©e standard...
- retourne vrai tant que √ßa re√ßoit des choses,
- une fois que √ßa arrive au bout du fichier (plus rien dans l'entr√©e standard) : renvoie faux -> permet de sortir de la boucle 

`read` lit son entr√©e standard **ligne par ligne** et le **renvoie dans une variable** (ici `LINE`).

**Avec cat et [[pipe|pipeline]]s (`|`) :**
```sh
cat monfichier.txt | while read -r LINE; do echo $LINE;
```

**Avec [[redirection vers et depuis des fichiers|redirection I/O]] (`<`) :**
```sh
while read -r LINE;
do
	echo $LINE;
done < monfichier.txt
```

ou en une ligne :  
```sh
while read -r LINE ; do ... done < monfichier.txt
```

cf [[read]].

---

## Wed 22.10.2025 : Web, HTTP, Lynx...

### Lynx

On teste des options de [[Lynx]]. 
1. R√©cup contenu textuel d'une page pour l'afficher (sans navigation)

Flemme de voir toutes les options de `lynx --help` donc je tente de trier avec `grep`.

```sh
$ lynx --help | grep "text"
  -base             prepend a request URL comment and BASE tag to text/html
  -dont_wrap_pre    inhibit wrapping of text in <pre> when -dump'ing and
  -justify          do justification of text (off)
  -list_inline      with -dump, forces it to show links inline with text (off)
  -preparsed        show parsed text/html with -source and in source view
  -syslog=text      information for syslog call
                    trim input text/textarea fields in forms (off)
```
-> pas s√ªre de trouver l√†... 

2. Retirer la liste des liens d'une page √† l'affichage.

```sh
$ lynx --help | grep "link"
  -hiddenlinks=[option]
                    hidden links: options are merge, listonly, or ignore
  -image_links      toggles inclusion of links for all images (off)
  -ismap            toggles inclusion of ISMAP links when client-side
  -link=NUMBER      starting count for lnk#.dat files produced by -crawl (0)
  -list_decoded     with -dump, forces it to decode URL-encoded links (on)
  -list_inline      with -dump, forces it to show links inline with text (off)
  -listonly         with -dump, forces it to show only the list of links (off)
  -nolist           disable the link list feature in dumps (off)
  -nonumbers        disable the link/form numbering feature in dumps (off)
  -number_fields    force numbering of links as well as form input fields (off)
  -number_links     force numbering of links (off)
  -prettysrc        do syntax highlighting and hyperlink handling in source
  -traversal        traverse all http links derived from startfile
  -underline_links  toggles use of underline/bold attribute for links (off)

```
--> idem pas trop s√ªre non-plus...

Les deux possibilit√©s n'ayant pas trop aid√©, on peut aussi tenter un `man lynx`.

1. On a trouv√© √ßa : 
```
   -dump  dumps the formatted output of  the  default  document  or  those
		  specified  on  the  command  line  to  standard  output.  Unlike
		  interactive mode, all documents are processed.  This can be used
		  in the following way:

			  lynx -dump http://www.subir.com/lynx.html

		  Files specified on the command line are  formatted  as  HTML  if
		  their  names  end  with one of the standard web suffixes such as
		  ‚Äú.htm‚Äù or ‚Äú.html‚Äù.  Use the -force_html option to  format  files
		  whose names do not follow this convention.
```

Possible d'aller v√©rifier son r√¥le en utilisant la "recherche" de `man`.

```
                          SEARCHING

  /pattern          *  Search forward for (N-th) matching line.
  ?pattern          *  Search backward for (N-th) matching line.
  n                 *  Repeat previous search (for N-th occurrence).
  N                 *  Repeat previous search in reverse direction.
  ESC-n             *  Repeat previous search, spanning files.
  ESC-N             *  Repeat previous search, reverse dir. & spanning files.
  ESC-u                Undo (toggle) search highlighting.
  ESC-U                Clear search highlighting.
  &pattern          *  Display only matching lines.

```

-> le `&pattern` fait un peu comme grep √† l'int√©rieur du man.
Le prof a dit qu'on pouvait faire "comme un ctrl+f" sur le web, mais pas trop s√ªre de comment le faire. utiliser `/pattern` ne me donne que la prochaine ocurrence...
- ah oui mais √ßa surligne quand-m√™me toutes les occurrences donc √ßa permet de voir rapidement.

En utilisant l'option `-dump`, le site s'affiche avec le texte uniquement (les liens sont nu√©mrot√©s), puis √† la fin une liste qui d√©taille le lien pour chaque num√©ro.

```sh
 lynx -dump plurital.org
```

Qui renvoie quelque chose du style : 
```
   [1][logo.jpg]
   [2]Accueil [3]Organisation du master [4]Candidatures et inscriptions
   [5]Rentr√©e [6]Liste pluriTAL [7]nexTAL - association d'√©tudiants
   [8]Archives [9]Annuaire
   Bienvenue sur le site du master pluriTAL

   Le master pluriTAL est cohabilit√© entre les trois partenaires suivants
   : Universit√© Sorbonne Nouvelle, Universit√© Paris Nanterre et INALCO.

   Vous trouverez ici toutes les informations li√©es √† l'organisation du
   master.

   Vous √™tes admis en master ? Rendez-vous dans la section [10]Rentr√©e
   pour pr√©parer votre arriv√©e !

   Pour toute information qui ne serait pas donn√©e sur le site, merci de
   contacter les [11]responsables p√©dagogiques ou l'[12]association
   nexTAL.

Prochains √©v√©nements

Rentr√©e 2025

   Mise-√†-jour 8 septembre : une pr√©sentation de l'install party est
   disponible sur la page de rentr√©e [13][ICI], le lien direct vers la
   pr√©sentation est [14][ICI].

   Pr√©-rentr√©e les 10 et 11 septembre 2025 !

   Au programme : r√©unions d'accueil M1 et M2 üë®‚Äçüè´, install party üë©‚Äçüíª,
   int√©gration M1 üïµÔ∏è et pot de rentr√©e nexTAL pour les M1 et M2 üéâ

   Plus d'informations [15]ICI.

   N'h√©sitez pas √† √©crire √† [16]nextal.contact@gmail.com en cas de
   question !

               [logo-p3.png] [logo-inalco.png] [logo-p10.png]

   [17]https://pluriTAL.org | pluriTAL ¬©2023, INALCO, Paris Nanterre,
   Sorbonne Nouvelle | Site g√©r√© par [18]nexTAL

References

   1. https://plurital.org/
   2. http://plurital.org/index.html
   3. http://plurital.org/organisation.html
   4. http://plurital.org/admin.html
   5. http://plurital.org/rentree.html
   6. http://plurital.org/groupepluriTAL.html
   7. http://plurital.org/nextal.html
   8. http://plurital.org/archives.html
   9. http://plurital.org/contact.html
  10. http://plurital.org/rentree.html
  11. http://plurital.org/contact.html#responsables
  12. http://plurital.org/nextal.html
  13. http://plurital.org/rentree.html#install-party
  14. http://plurital.org/install-party.pdf
  15. http://plurital.org/rentree.html
  16. mailto:nextal.contact@gmail.com
  17. https://plurital.org/
  18. mailto:nextal.contact@gmail.com

```

2. Enlever les liens

√Ä partir de la version "dump√©e" du site web, on peut filtrer avec `-nolist` pour enlever la liste de liens √† la fin.

```sh
lynx -dump -nolist plurital.org
```

Qui renvoit donc : 
```
   [logo.jpg]
   
   Accueil Organisation du master Candidatures et inscriptions Rentr√©e
   Liste pluriTAL nexTAL - association d'√©tudiants Archives Annuaire
   Bienvenue sur le site du master pluriTAL

   Le master pluriTAL est cohabilit√© entre les trois partenaires suivants
   : Universit√© Sorbonne Nouvelle, Universit√© Paris Nanterre et INALCO.

   Vous trouverez ici toutes les informations li√©es √† l'organisation du
   master.

   Vous √™tes admis en master ? Rendez-vous dans la section Rentr√©e pour
   pr√©parer votre arriv√©e !

   Pour toute information qui ne serait pas donn√©e sur le site, merci de
   contacter les responsables p√©dagogiques ou l'association nexTAL.

Prochains √©v√©nements

Rentr√©e 2025

   Mise-√†-jour 8 septembre : une pr√©sentation de l'install party est
   disponible sur la page de rentr√©e [ICI], le lien direct vers la
   pr√©sentation est [ICI].

   Pr√©-rentr√©e les 10 et 11 septembre 2025 !

   Au programme : r√©unions d'accueil M1 et M2 üë®‚Äçüè´, install party üë©‚Äçüíª,
   int√©gration M1 üïµÔ∏è et pot de rentr√©e nexTAL pour les M1 et M2 üéâ

   Plus d'informations ICI.

   N'h√©sitez pas √† √©crire √† nextal.contact@gmail.com en cas de question !

               [logo-p3.png] [logo-inalco.png] [logo-p10.png]

   https://pluriTAL.org | pluriTAL ¬©2023, INALCO, Paris Nanterre, Sorbonne
   Nouvelle | Site g√©r√© par nexTAL

```

Et si cette commande `-nolist` n'existait pas, on pourrait regarder de plus pr√®s √† quoi ressemble le dump. 
-> En identifiant **√† quoi ressemblent les lien**, on peut utiliser des **expressions r√©guli√®res** ([[expression r√©guli√®re|Regex]]) pour enlever les liens (https:// ... et adresse-mails).

On peut rep√©rer que dans notre dump, **les liens ressemblent √† des lignes avec un num√©ro**, un point, et le lien.
```sh
lynx -dump plurital.org | grep -P '\d+\. (http|mailto)'
```

Description de la partie `grep` : 
- option `-P` (pour Pearl ?) permet d'utiliser ici les expressions r√©guli√®res.
- `'\d+\. http'`
	- `\d+` (plusieurs chiffres, *digits*)
	- suivi d'un point et espace `\. `
	- `(http|mailto)` puis soit d'un http (url) soit d'un mailto (adresse-mail)

---

### Curl

L√† ou `lynx` r√©cup√®re le *contenu* d'une page web, les commandes `wget` et `curl` sont l√† pour r√©cup√©rer des *pages web compl√®tes avec m√©tadonn√©es*.

`curl` permet de r√©cup√©rer des [[m√©tadonn√©es]] sur la page web, sur les requ√™tes qu'on envoie. 
- permet de savoir si la page web est **valide**...
- concr√®tement √ßa se pr√©sente comme le code html de la page

```sh
curl <URL>
```

Avec `<URL>` une URL vers une page sur le web.

Un exemple int√©ressant : 
```sh
$ curl google.com
<HTML><HEAD><meta http-equiv="content-type" content="text/html;charset=utf-8">
<TITLE>301 Moved</TITLE></HEAD><BODY>
<H1>301 Moved</H1>
The document has moved
<A HREF="http://www.google.com/">here</A>.
</BODY></HTML>
```
-> Ici on voit qu'en r√©alit√© quand on tape juste `google.com` √ßa nous renvoie vers une page google √©crite "mieux".

*Note sur le worldwideweb (www)* : de base on voulait diff√©rencier les sites sur le worldwideweb (accessibles √† tous) de ceux qui peuvent √™tre locaux (genre localhost et tout).


**Options :** 

| Option | R√¥le                                    | ex                                                               |
| ------ | --------------------------------------- | ---------------------------------------------------------------- |
| `-L`   | pour suivre un d√©placement/ redirection | par exemple sur `google.com`, √ßa va sur `http://www.google.com/` |
| `-i`   | avoir les options d'en-t√™te / headers   | Location : ...<br>Content-Type : ... (pr√©cise le char-set)       |

Les options sont *combinables*.

On peut aussi voir les m√©tadonn√©es de la requ√™te.

---

Sinon j'ai pu installer un LSP (Language Server Protocol) avec nodejs et npm pour avoir des informations sur les fonctions que j'utilise dans Kate et √ßa c'est vraiment hyper pratique !!!


### Mini-projet

#### **Exercice 1**
1. Pourquoi √©viter `cat` ?
   Honn√™tement vous avez mentionn√© √ßa en cours mais j'ai pas bien compris, seulement entendu je crois que √ßa avait un rapport avec les retours √† la ligne ?

Mais quand j'ai essay√© de faire des mini-tests en local pour voir la diff√©rence, je ne l'ai pas trop vue.
J'ai fait : 
```bash
cat monfichier.txt | while read -r LINE; do echo "nouvelle ligne ${LINE}"; done
```
et 
```bash
while read -r LINE; do  echo "nouvelle ligne ${LINE}"; done < monfichier.txt
```

Et les deux m'ont donn√© le m√™me r√©sultat : 
```
nouvelle ligne j'√©cris des lignes.
nouvelle ligne L√† c'est une deuxi√®me ligne. Est-ce que tu me vois avec la premi√®re ?
nouvelle ligne Et moi je suis la troisi√®me.
nouvelle ligne 
nouvelle ligne 
nouvelle ligne 
nouvelle ligne Moi je suis la 4√®me ligne de texte, mais il y a ds sauts de ligne avant moi. Qu'est-ce que tu vois avec cat et avec echo en me lisant ?
```

Mais peut-√™tre que vous ne parliez pas de mettre cat puis pipeline au lieu d'utiliser une redirection, mais plut√¥t d'utiliser `cat` l√† o√π on a utilis√© `echo` ?
Par curiosit√© j'ai test√© √ßa : 
```bash
while read -r LINE; do  cat ${LINE}; done < exercices/monfichier.txt
```
Mais √ßa semble vraiment vraiment pas √™tre quelque chose √† faire, car l√† o√π `echo` prend en argument une chaine (comme `LINE` ici), `echo`  prend, lui, en argument un nom de fichier. 

Donc l√† en fait √ßa a essay√© d√©sesp√©r√©ment de lire le contenu de mon petit fichier test comme un chemin:
```
cat: "j'√©cris": No such file or directory
cat: des: No such file or directory
cat: lignes.: No such file or directory
cat: L√†: No such file or directory
cat: "c'est": No such file or directory
cat: une: No such file or directory
cat: deuxi√®me: No such file or directory
cat: ligne.: No such file or directory
cat: Est-ce: No such file or directory
cat: que: No such file or directory
cat: tu: No such file or directory
cat: me: No such file or directory
cat: vois: No such file or directory
cat: avec: No such file or directory
cat: la: No such file or directory
cat: premi√®re: No such file or directory
cat: '?': No such file or directory
cat: Et: No such file or directory
cat: moi: No such file or directory
cat: je: No such file or directory
cat: suis: No such file or directory
cat: la: No such file or directory
cat: troisi√®me.: No such file or directory


Moi je suis la 4√®me ligne de texte, mais il y a ds sauts de ligne avant moi. Qu'est-ce que tu vois avec cat et avec echo en me lisant ?
```

Conclusion : je ne sais pas. ü§∑


2. Transformer `"urls/fr.txt"` en param√®tre du script et valider sa pr√©sence.

Code de base : 
```bash
while read -r line;
do
	echo ${line};
done < "urls/fr.txt";
```

Au lieu de mettre directement "urls/fr.txt" dans la redirection, on y glisse un **param√®tre donn√© au script** quand on le lance, et on valide au passage sa pr√©sence : 

```bash
URLS=$1 # param√®tre du script (chemin du fichier d'URLs)

while read -r line;
do
	echo ${line};
done < ${URLS} # read lit le fichier en param√®tre
```
‚ö†Ô∏è au d√©but j'avaisoubli√© de noter `${URLS}`, j'avais juste mis `URLS` mais c'est pas comme √ßa qu'on *appelle* les variables en bash.

On peut de plus rajouter au d√©but une boucle `if` avec une condition sur le nombre de param√®tres donn√©s (`$#`) pour **arr√™ter le code si on n'a pas donn√© un argument au script** (gr√¢ce √† `exit`).
```bash
# V√©rification qu'on a bien un param√®tre au script
if [ $# - ne 1 ] # nombre total d'arguments n'est pas 1
then
	echo "Donnez un param√®tre (chemin vers fichier avec URLs)"
	exit
fi
```

3. Comment afficher le num√©ro de ligne avant chaque URL (sur la m√™me ligne, valeurs s√©par√©es par des tabulations) ?
   On peut ajouter un compteur qu'on incr√©mente √† chaque nouvelle `line` (correspondant √† des URLs) lue, je suppose.

```bash
N=0 # compteur d'URL
URLS=$1

while read -r line;
do
	N=$(expr $N + 1) # on utilise la "calculatrice" pour incr√©menter N
	echo -e "${N}\t${line}" # affichage avec tabulation entre le n¬∞ et l'URL
done < ${URLS}
```

> [!Info] Affichage de caract√®res sp√©ciaux (tabulations)
> ‚ö†Ô∏è j'ai du rajouter l'option `-e` √† `echo` que je n'avais pas mise de base et qui permet d'activer l'interpr√©tations de caract√®res √©chap√©s (par ex. `\t` pour pettre une tabulation) et √ßa marche ! SInon √ßa affichait "\t".

R√©sultat : 
```
1	https://fr.wikipedia.org/wiki/Robot
2	https://fr.wikipedia.org/wiki/Robot_de_cuisine
3	fr.wikipedia.org/wiki/Robot_d%27indexation
4	https://fr.wikipedia.org/wiki/Bot_informatique
5	https://fr.wikipedia.org/wiki/Atlas_(robot)
6	https://roboty.magistry.fr
7	https://fr.wikipedia.org/wiki/Robot_(Leonard_de_Vinci)
8	https://fr.wiktionary.org/wiki/robot
9	https://fr.wikipedia.org/wiki/Protocole_d%27exclusion_des_robots
10	https://fr.wikipedia.org/wiki/Robotique
```

#### **Exercice 2**

Apr√®s l'exo 1, on rajoute des infos √† chaque ligne, qu'on va r√©cup√©rer avec les fonctions qu'on a vues en cours, √† savoir ici plut√¥t [[cURL]], qui permet de r√©cup√©rer avec l'option `-i` des m√©tadonn√©es sur le code statut de la requ√™te HTTP (ex : 200 r√©ussite, 5xx serveur) ou sur l'encodage de la page.

M√©tadonn√©es √† rajouter :
1. [x] Code HTTP de r√©ponse (gestion des erreurs possible).  [completion:: 2025-10-28]
2. [x] Encodage de la page (si d√©tect√©).  [completion:: 2025-10-28]
3. [x] Nombre de mots dans la page.  [completion:: 2025-10-28]

.
1/2. **Code HTTP et encodage de la page**

En utilisant `curl -i <URL>` on r√©cup√®re des interactions avec le serveur. Je regarde √† quoi ressemble une page  : 

```bash
curl -i https://fr.wikipedia.org/wiki/Robot
```

Cette ligne donne dans les premi√®res lignes (avant le *contenu* r√©el de la page) les m√©tadonn√©es suivantes d'interaction avec le serveur : 

```
TP/2 200 
date: Sun, 26 Oct 2025 10:34:32 GMT
server: ATS/9.2.11
x-content-type-options: nosniff
content-language: fr
accept-ch: 
last-modified: Wed, 22 Oct 2025 22:42:56 GMT
content-type: text/html; charset=UTF-8
age: 23417
accept-ranges: bytes
x-cache: cp6015 hit, cp6009 hit/23
```

Ici on y voit deux lignes qui nous int√©ressent : 

| Ligne d'int√©r√™t dans l'exemple           | On veut quoi ?                                   |
| ---------------------------------------- | ------------------------------------------------ |
| `TP/2 200`                               | Le `200` en fin de ligne = code HTTP de r√©ponse. |
| `content-type: text/html; charset=UTF-8` | `UTF-8` = encodage de la page.                   |

On peut chercher √† les r√©cup√©rer en utilisant par exemple une [[expression r√©guli√®re]] appliqu√©e sur la sortie de `curl -i <URL>`. Pour √ßa, je vais d'abord regarder quelques autres exemples d'URL pour voir le type de formes que peuvent prendre ces lignes d'int√©r√™t et rep√©rer les motifs qui se reproduisent, √† chercher avec une regex.

Exemple sur une autre adresse : 
```
TP/2 200 
date: Fri, 24 Oct 2025 19:39:49 GMT
server: mw-web.eqiad.main-767875d469-7xxss
x-content-type-options: nosniff
content-language: fr
accept-ch: 
last-modified: Wed, 15 Oct 2025 09:45:57 GMT
content-type: text/html; charset=UTF-8
age: 163835
accept-ranges: bytes
```

A partie des autres tests faits en cours, j'ai quand-m√™me l'impression qu'on aura toujours : 
- code HTTP : premi√®re ligne (3 digits en fin de ligne apr√®s  un espace)
- encodage : apr√®s le mot-cl√© `charset=` (ex: `charset=ISO-8859-1`, `charset=UTF-8` ).

Dans l'id√©e, j'aimerais rajouter au code pr√©c√©dent, dans la boucle `while read`, pour chaque ligne, une recherche avec `curl -i <URL>` sur la ligne (`line`) active qui correspond √† une URL, pour trouver ce code http et l'encodage.

Une version tr√®s simple est juste de r√©cup√©rer la premi√®re ligne (avec [[head]]) puis de [[grep]] sur "charset". 
Mais en fait je viens de tester par exemple de faire :
```bash
curl -i https://fr.wikipedia.org/wiki/Robot | head -n 1
```
Et √ßa ne marche pas vraiment. √áa nous affiche √ßa : 
```
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0HTTP/2 200 
  5  246k    5 13069    0     0  38604      0  0:00:06 --:--:--  0:00:06 38551
curl: (23) Failure writing output to destination
```

Cela dit, on y trouve bien la ligne HTTP/2 200.

Dans les autres options que je "connais" de curl, il y a le `-o` pour sp√©cifier un fichier de sortie. Je teste d'√©crire le r√©sultat dans un fichier plut√¥t que le terminal : 
```bash
curl -i -o test.txt https://fr.wikipedia.org/wiki/Robot
```
Cette fois-ci, quand j'applique `head -n 1 text.txt`, j'obtiens bien ce que je voulais pr√©c√©demment (`HTTP/2 200`).
Et `grep "charset" test.txt` me renvoie : 
```
content-type: text/html; charset=UTF-8
<meta charset="UTF-8">
```
Pour √©viter d'avoir deux fois la m√™me info, j'appliquerai peut-√™tre un `head -n 10` sur la sortie avant de `grep` "charset" pour √™tre s√ªre d'uniquement cherchet dans les bandeaux informatifs de d√©but (li√©s √† l'option `-i`). Ou alors, je pourrais aussi voir s'il n'y a pas une option pour n'avoir que les headers ?

Mais je me demande s'il ne faut pas aussi avoir une sorte d'option comme la `-dump` de [[lynx]] avant de pouvoir faire des traitements sur le texte des m√©tadonn√©es.
Je vois une option : 
```
-D, --dump-header <filename>
  (HTTP  FTP) Write the received protocol headers to the specified
  file. If no headers are received, the use of this option creates
  an empty file.

  When used in FTP, the FTP server response lines  are  considered
  being "headers" and thus are saved there.

  Having  multiple  transfers  in  one set of operations (i.e. the
  URLs in one -:, --next clause), appends them to the  same  file,
  separated by a blank line.

```
En r√©alit√© √ßa n'a pas du tout l'air d'avoir la m√™me action que l'option `-dump` de lynx. Cela dit, si l'id√©e ici est que je peux par exemple sp√©cifier les "headers" : "HTTP" et "content-type" pour avoir le code de statut et l'encodage, √ßa peut √™tre vraiment super :D

Apr√®s test, il semble que l'option `-D` se pr√©sente comme tel : 
```bash
curl -D fichier_sortie.txt <URL>
```
En √©crivant dans `fichier_sortie.txt` uniquement les "headers" (code statut, date, server, ..., content-type, ...)

Une version qui peut marcher pour le moment est de faire un fichier temporaire pour chaque URL (qu'on √©crase √† chaque nouvelle URL et supprime en fin de script) dans lequel on applique les recherches... Il y a s√ªrement une version "plus efficace" avec des pipes par exemple pour ne pas avoir √† cr√©er de fichier temporaire mais c'est mieux que rien pour le moment.

---

Maintenant qu'on a trouv√© des m√©thodes pour ce qu'on voulait faire, on pimpe un peu la boucle pr√©c√©dente : 

```bash
N=0 # compteur d'URL
URLS=$1

while read -r line;
do
	N=$(expr $N + 1) # incr√©ment
	
	# Nouvelles lignes pour exo 2
	# On va r√©cup√©rer les m√©tadonn√©es en ex√©cutant curl
	
	# on extrait les infos des headers dans un fichier temporaire
	# line est une URL
	curl -D temp.txt ${line}
	METADONNEES="temp.txt"
	
	CODE_HTTP=$(head -n 1 ${METADONNEES}) # lit la 1√®re ligne	
	CONTENT=$(grep "charset" ${METADONNEES})
	
	# on affiche les donn√©es extraites espac√©es par des tabulations
	echo -e "${N}\t${line}\t${CODE_HTTP}\t${CONTENT}" 
done < ${URLS}

# on supprime le fichier temporaire cr√©√©
rm temp.txt 
```

Trucs qui m'emb√™tent : 
- en fait quand je fais `-D`, m√™me si √ßa m'√©crit les headers dans un fichier, **√ßa me met la page dans le terminal** donc √ßa me bloque un peu ce que je veux voir... solutions possibles : 
	- rediriger sortie standard vers un autre fichier temporaire que je supprime, pour ne pas polluer ce que je veux afficher
	- ou voir quelle option me permet de ne rien afficher... -> `-s` silent mode ??
		- Apr√®s cherch√© un peu plus dans les options, il se trouve qu'en fait l'option `-I` est exactement ce que je cherchais puisqu'elle permet de ne garder que les "headers".

**Utilisation de `-I` puis post-processing**
En tapant 
```bash
curl -I  https://fr.wikipedia.org/wiki/Robot | head -n 1
```
J'obtiens : 
```
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0  246k    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
HTTP/2 200 
```
Donc je n'ai pas que la ligne d'int√©r√™t, mais aussi d'autres infos... que je n'ai √©tonnamment pas quand j'affiche juste `curl -I <URL>`. Je suis un peu perdue l√†...

En grosse magouilleuse, j'ai voulu voir si je pouvais juste garder uniquement la derni√®re ligne de ce que je viens d'afficher, alors j'ai fait √ßa : 
```bash
curl -I  https://fr.wikipedia.org/wiki/Robot | head -n 1 | tail -n 1
```
Mais √ßa m'affiche, l√† encore, ceci : 
```bash
curl -I  https://fr.wikipedia.org/wiki/Robot | head -n 1 | tail -n 1
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0  246k    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
HTTP/2 200 
```

Donc en fait je pense que se m√©langent ici le fait que, potentiellement, utiliser `curl` affiche dans tous les cas √† l'√©cran des infos (% Total, % Received, ...), qui s'affiche donc √† c√¥t√© du r√©sultat de `tail`.
A voir si je ne peux pas r√©orienter (again) la sortie standard...

... (recherches)

Finalement √ßa marche de faire √ßa : 
```bash
curl -s -I  https://fr.wikipedia.org/wiki/Robot | head -n 1
```
pour avoir juste √ßa : `HTTP/2 200`.

Le souci de l'option `-D` √©tait que √ßa me permettait de mettre les infos de headers dans un fichier, et √ßa affichait dans la sortie standard le corps de la page.
La version silencieuse `-s` (silent) permet de plus de ne pas afficher les informations de progression de curl (les lignes `% Total`, `% Received`, etc., qui sont √©crites sur la sortie d'erreur standard).

En fait plut√¥t que de faire un fichier temporaire du coup je peux juste rediriger dans le code la sortie standard vers une variable.

Je remplace la boucle `while` comme √ßa : 
```bash
while read -r line;
do
	N=$(expr $N + 1) # incr√©ment

	# Nouvelles lignes pour exo 2

	# On va r√©cup√©rer les m√©tadonn√©es en ex√©cutant curl (line est une URL)
	METADONNEES=$(curl -s -I ${line})

	CODE_HTTP=$(echo "${METADONNEES}" | head -n 1 ) # lit la 1√®re ligne
	ENCODING=$(echo "${METADONNEES}" | grep "charset")

	# on affiche les donn√©es extraites espac√©es par des tabulations
	echo -e "${N}\t${line}\t${CODE_HTTP}\t${ENCODING}"

done < ${URLS};
```

√áa m'a fait un vraiment dr√¥le de r√©sultat... 
```
1	content-type: text/html; charset=UTF-8	HTTP/2 200 
2	content-type: text/html; charset=UTF-8_cuisine	HTTP/2 200 
3	fr.wikipedia.org/wiki/Robot_d%27indexation	HTTP/1.1 301 Moved Permanently
4	content-type: text/html; charset=UTF-8rmatique	HTTP/2 200 
5	content-type: text/html; charset=UTF-8obot)	HTTP/2 200 
6	https://roboty.magistry.fr		
7	content-type: text/html; charset=UTF-8eonard_de_Vinci)	HTTP/2 404 
8	content-type: text/html; charset=UTF-8	HTTP/2 200 
9	https://fr.wikipedia.org/wiki/Protocole_d%27exclusion_des_robots	HTTP/2 20content-type: text/html; charset=UTF-8
10	content-type: text/html; charset=UTF-8e	HTTP/2 200 
```
La partie "ENCODING" semble s'√™tre comme "coll√©e sur" l'URL. Je ne sais pas trop d'o√π c'est venu... mettre des guillements autour de `'${ENCODING}'` ne change rien. En revanche, elle n'√©crase que la 2√®me colonne (pas le nombre, pas le code HTTP). ...

En parall√®le je me suis renseign√©e sur les Regex, car dans tous les cas j'avais la ligne enti√®re d'info (respectivement "TP/2 200 " et  "content-type: text/html; charset=UTF-8"). Or, moi j'aimerais bien savoir comment r√©cup√©rer plus finement juste le charset (enfin ce qui suit charset=), ou juste le code digital de la premi√®re ligne...
De plus, dans le cas des erreurs, il peut √™tre int√©ressant de r√©cup√©rer aussi le message d'erreur qui suit le code HTTP √† 3 chiffres.

Une possibilit√© : 
```bash
curl -s -I <URL> | grep -i 'content-type:' | grep -oP 'charset=\K[^; ]+'
```

O√π : 
- on ex√©cute d'abord curl avec les options `-s` et `-I` comme vu pr√©c√©demment pour r√©cup√©rer ls headers seuls.
- l'option `-i` de grep le rend insensible √† la casse -> on s√©lectionne la ligne qui parle d'encodage (avec 'content-type").
- puis on utilise grep √† nouveaux pour faire une regex avec les options `-o` et `-P` cumul√©es : 
	- `-o` permet de n'afficher **que la partie de la ligne qui correspond au motif** (et non toute la ligne comme le fait normalement grep).
	- `-P` active les expressions r√©guli√®res compatibles avec Perl.
	- On affiche qu'on cherche le motif `'charset=\K[^; ]+'`:
		- motif commen√ßant par `charset=`, suivi de plusieurs (`+`) caract√®res qui ne sont ni (indiqu√© par `^`) un point virgule ni un espace (c√†d, le mot qui suit)~~, ni un antislash (qui indique probablement un retour en d√©but de ligne - cf probl√®me d'apr√®s qu'on voudra √©viter aussi pour le petit 3)~~.
		- **`\K` permet d'indiquer qu'on ne retient que la suite qui a match√©**. On ne garde pas ce qui √©tait avant ("reset match").

Bon, par contre j'ai toujours mon souci de tabulations qui se font manger...

J'ai √ßa : 
```
1	UTF-8://fr.wikipedia.org/wiki/Robot	HTTP/2 200 
2	UTF-8://fr.wikipedia.org/wiki/Robot_de_cuisine	HTTP/2 200 
3	fr.wikipedia.org/wiki/Robot_d%27indexation	HTTP/1.1 301 Moved Permanently
4	UTF-8://fr.wikipedia.org/wiki/Bot_informatique	HTTP/2 200 
5	UTF-8://fr.wikipedia.org/wiki/Atlas_(robot)	HTTP/2 200 
6	https://roboty.magistry.fr		
7	UTF-8://fr.wikipedia.org/wiki/Robot_(Leonard_de_Vinci)	HTTP/2 404 
8	UTF-8://fr.wiktionary.org/wiki/robot	HTTP/2 200 
9	https://fr.wikipedia.org/wiki/Protocole_d%27exclusion_des_robots	HTTP/2 20UTF-8
10	UTF-8://fr.wikipedia.org/wiki/Robotique	HTTP/2 200 
```

Une hypoth√®se est que quand je r√©cup√®re la ligne avec le code de statut, √ßa me r√©cup√®re aussi le retour au d√©but de ligne (colonne 1), et l `\t` suivant ram√®ne donc √† la colonne 2. 
J'ai cherch√© une option pour ne r√©cup√©rer que le code XXX. `awk` semble permettre de d√©couper un texte qu'on lui donne selon les s√©parateurs classiques (points-virgule, espaces...) et les consid√®re comme des variables utilisables localement.
En runnant √ßa : 
```bash
CODE_HTTP=$(echo "${METADONNEES}" | head -n 1 | awk '{print $2}') # lit la 1√®re 
```
Normalement on ne garde qu le deuxi√®me "mot" de la ligne "HTTP/2 200". J'ai aussi espoir que √ßa enl√®ve le retour au d√©but de ligne potentiel.

ü•Åü•Åü•Å (roulement de tambours)

Oui comme √ßa √ßa marche !! J'obtiens √ßa : 
```
1	https://fr.wikipedia.org/wiki/Robot	200	UTF-8
2	https://fr.wikipedia.org/wiki/Robot_de_cuisine	200	UTF-8
3	fr.wikipedia.org/wiki/Robot_d%27indexation	301	
4	https://fr.wikipedia.org/wiki/Bot_informatique	200	UTF-8
5	https://fr.wikipedia.org/wiki/Atlas_(robot)	200	UTF-8
6	https://roboty.magistry.fr		
7	https://fr.wikipedia.org/wiki/Robot_(Leonard_de_Vinci)	404	UTF-8
8	https://fr.wiktionary.org/wiki/robot	200	UTF-8
9	https://fr.wikipedia.org/wiki/Protocole_d%27exclusion_des_robots	200	UTF-8
10	https://fr.wikipedia.org/wiki/Robotique	200	UTF-8
```

`awk` outil pratique √† retenir, super pour d√©couper. Il me semble par contre que a run dans un autre shell (comme `gawk`, mais j'en sais trop rien je ne connais que de loin)... peut-√™tre pas le plus efficace. De plus je suppose qu'on devait pouvoir le faire uniquement avec les commandes qu'on a vues jusqu'ici ?

Peut-√™tre faisable aussi avec regex... je peux essayer par exemple de faire un peu comme tout √† l'heure avec 'charset' en disant que je prends le motif qui suit un espace (dans la premi√®re ligne isol√©e) et que je m'arr√™te quand j'ai un caract√®re sp√©cial, style `\`. Voire m√™me, je peux juste dire que je veux trois caract√®res je crois ??

```bash
CODE_HTTP=$(echo "${METADONNEES}" | head -n 1 | grep -oP " \K\d{3}")
```
Il me semble que comme √ßa √ßa permet de rep√©rer un motif du style espace suivi de 3 chiffres, en enlevant l'espace (gr√¢ce au `\K`).

Par contre, un peu dommage en fait (mais c'√©tait le cas aussi au-dessus) que je perde les √©ventuels messages qui suivent le code statut.

Je teste... ‚Üí √áa marche aussi ! ü•≥

J'aurai vraiement gal√©r√©. 

Et maintenant : 

3. **Nombre de mots dans la page**

L√† franchement je pense juste faire un `lynx -dump -nolist` (comme on a vu en cours pour n'avoir que le contenu de la page sans liens) avec un pipe dans `wc` pour compter les mots (`-w`).

Et j'ai rajout√© une petite ligne d'en-t√™tes au tout d√©but : 
```bash
echo -e "N\tURL\tStatut HTTP\tEncodage\tNb mots"
```


**Nouveaux soucis :** 
1. on a de nouveau le probl√®me de retour au d√©but que j'avais avec la ligne de code de statut, qui se pase √† la fin de la ligne avec le charset...:
```
N	URL	Statut HTTP	Encodage	Nb mots
1	5681s://fr.wikipedia.org/wiki/Robot	200	UTF-8
2	1161s://fr.wikipedia.org/wiki/Robot_de_cuisine	200	UTF-8
3	fr.wikipedia.org/wiki/Robot_d%27indexation	301		1765
4	2583s://fr.wikipedia.org/wiki/Bot_informatique	200	UTF-8
5	1167s://fr.wikipedia.org/wiki/Atlas_(robot)	200	UTF-8

Looking up roboty.magistry.fr
Making HTTPS connection to roboty.magistry.fr

lynx: Can't access startfile https://roboty.magistry.fr/
6	https://roboty.magistry.fr			0
7	440ps://fr.wikipedia.org/wiki/Robot_(Leonard_de_Vinci)	404	UTF-8
8	4807s://fr.wiktionary.org/wiki/robot	200	UTF-8
9	https://fr.wikipedia.org/wiki/Protocole_d%27exclusion_des_robots	200	10588
10	13023://fr.wikipedia.org/wiki/Robotique	200	UTF-8
```
Le seul endroit o√π le probl√®me ne survient pas est lorqu'on n'a pas de charset donn√©.

Une solution : mon probl√®me semble √™tre un "carriage return" qu'on peut enlever avec `tr -d '\r'` (cf https://stackoverflow.com/questions/800030/remove-carriage-return-in-unix).

Je l'ins√®re dans mon code. Maintenant j'ex√©cute curl comme suit :
```bash
METADONNEES=$(curl -s -I ${line} | tr -d '\r')
```

√áa marche ! 

Par contre √ßa a r√©solu seulement mon probl√®me 1, et pas mon probl√®me 2 :
2. mauvaise gestion au niveau de https://roboty.magistry.fr, erreur non prise en charge pour le moment...

R√©sultat actuel : 
```
N	URL	Statut HTTP	Encodage	Nb mots
1	https://fr.wikipedia.org/wiki/Robot	200	UTF-8	5681
2	https://fr.wikipedia.org/wiki/Robot_de_cuisine	200	UTF-8	1161
3	fr.wikipedia.org/wiki/Robot_d%27indexation	301		1765
4	https://fr.wikipedia.org/wiki/Bot_informatique	200	UTF-8	2583
5	https://fr.wikipedia.org/wiki/Atlas_(robot)	200	UTF-8	1167

Looking up roboty.magistry.fr
Making HTTPS connection to roboty.magistry.fr

lynx: Can't access startfile https://roboty.magistry.fr/
6	https://roboty.magistry.fr			0
7	https://fr.wikipedia.org/wiki/Robot_(Leonard_de_Vinci)	404	UTF-8	440
8	https://fr.wiktionary.org/wiki/robot	200	UTF-8	4807
9	https://fr.wikipedia.org/wiki/Protocole_d%27exclusion_des_robots	200	UTF-8	1058
10	https://fr.wikipedia.org/wiki/Robotique	200	UTF-8	13023
```

Pour le code suivant : 

```bash
#!/bin/bash

# V√©rification qu'on a donn√© un argument
if [ $# -ne 1 ] # teste si nb d'argument diff√©rent de 1
then
	echo "Donner un param√®tre (chemin vers fichier d'URLs)"
	exit # fin de programme
fi

N=0 	# compteur d'URLs
URLS=$1

echo -e "N\tURL\tStatut HTTP\tEncodage\tNb mots"

while read -r line;
do
	N=$(expr $N + 1) # incr√©ment

	# Nouvelles lignes pour exo 2

	# On va r√©cup√©rer les m√©tadonn√©es en ex√©cutant curl (line est une URL)
	METADONNEES=$(curl -s -I ${line} | tr -d '\r')

	# code de statut
# 	CODE_HTTP=$(echo "${METADONNEES}" | head -n 1 | awk '{print $2}') # lit la 1√®re ligne
	CODE_HTTP=$(echo "${METADONNEES}" | head -n 1 | grep -oP " \K\d{3}")

	# encodage : on fait une regex
	ENCODING=$(echo "${METADONNEES}" | grep -i "content-type" | grep -oP "charset=\K[^; ]+")

	NB_MOTS=$(lynx -dump -nolist ${line} | wc -w)

	# on affiche les donn√©es extraites espac√©es par des tabulations
	echo -e "${N}\t${line}\t${CODE_HTTP}\t${ENCODING}\t${NB_MOTS}"

done < ${URLS};
```


Pour le moment, je ne vais pas r√©ussir √† faire mieux. J'ai d√©j√† un jour de retard (j'√©tais en train de d√©m√©nager...) alors je poste √ßa et je verrai bien la correction. :)


---

## Wed 05.11.2025 

Cours [[HTML]], [[Balisage]], puis r√©√©criture du [[mini-projet PPE]] sous forme de [[tableau HTML]].

### Consignes miniprojet-2
**Deadline** : lundi 10.11.2025 √† 23h59.

**Exercice :** Transformer la sortie tabulaire du [[mini-projet PPE]] en [[tableau HTML]].
On va transformer la sortie tabulaire en sortie au format HTML. Il faut donc cr√©r un fichier .html qui contiendra : 
1. un ent√™te (`head`)
2. un corps (`body`)
	- Devra contenir au moins le tableau des donn√©es r√©cup√©r√©es, avec une ligne d'en-t√™te et les r√©sultats pour chaque URL

Ce code HTML doit √™tre √©crit dans un fichier `.html` qui doit √™tre lisible par un navigateur web quelconque.
Le tableau doit se situer au chemin : `PPE1-2025/miniprojet/tableaux/tableau-fr.html`.

**Petites √©tapes :** 
- [x] **miniprojet-2** ‚è´ üìÖ 2025-11-11 ‚úÖ 2025-11-10
	- [x] corriger le code au besoin ~~(comme moi il marchait bien je pense simplement cr√©er un tag sur le m√™me commit) ~~ ‚úÖ 2025-11-10
		- [x] transformer la sortie en sortir TSV plut√¥t que juste des donn√©es affich√©es sur l'√©cran ? (√† mettre dans `tableaux/`) ‚úÖ 2025-11-10
		- [x] tag **miniprojet-1-revu** ([[git tag]]) ‚úÖ 2025-11-10
	- [x] faire exos du miniprojet sur son d√©p√¥t individuel : ‚úÖ 2025-11-10
		- [x] transformer la sortie TSV en [[HTML]] ‚úÖ 2025-11-10
			- [x] cr√©er ent√™te ‚úÖ 2025-11-10
			- [x] cr√©er corps ‚úÖ 2025-11-10
				- [x] ent√™te de table ‚úÖ 2025-11-10
				- [x] cr√©ation d'une ligne pour chaque URL ‚úÖ 2025-11-10
		- [x] supprimer le TSV de mon d√©p√¥t ‚úÖ 2025-11-10
		- *bonus* : faire feuille d'exos sur comptage de mots / bigrammes ‚Üí y'a pas la feuille d'exos
	- [x] cr√©er le tag **miniprojet-2** √† la fin du travail et le push sur Github ‚úÖ 2025-11-10
	- ~~cr√©er un fichier texte avec le lien github vers le tag **miniprojet-2**~~

Mon 10.11.2025
De retour pour vous jouer un mauvais tour ! je viens modifier mon code de la derni√®re fois, parce que j'avais affich√© √† l'√©cran le tableau d'informations, mais apparemment il fallait le faire dans un fichier TSV.

Je vais tenter de juste rajouter un `touch tableau-fr.tsv` au d√©but du programme puis de remplacer les commandes de type `echo ...` en `echo ... >> tableau-fr.tsv` pour rajouter les lignes en fin de fichier.
- [x] √† voir s'il faudra rajouter des sauts de ligne ou s'ils sont automatiques d'un ajout √† l'autre. ‚úÖ 2025-11-10
	- √ßa a march√© nickel sans avoir besoin de changer quoi que ce soit d'autre ! (enfin j'avais juste oubli√© de mettre le fichier cr√©√© dans le r√©pertoire tableaux mais sinon nickel)
	- en plus pratique, a permet de s√©parer les informations de sortie standard d'erreur (affich√©es dans le terminal) de celles que je veux stocker dans le tsv.
	- finalement j'ai cr√©√© une tariable avec le nom de fichier pour ne pas avoir √† redonner le chemin √† chaque fois

Par contre ! j'ai voulu tester et effectivement j'ai un l√©ger souci sur le fait que comme j'√©cris √† la fin du fichier donn√© (`>>`), si j'ex√©cute plusieurs fois le programme, je rajoute juste des lignes au lieu de r√©√©crire le fichier.
*Exemple :* 

| N   | URL                                                              | Statut HTTP | Encodage | Nb mots |
| --- | ---------------------------------------------------------------- | ----------- | -------- | ------- |
| 1   | https://fr.wikipedia.org/wiki/Robot                              | 200         | UTF-8    | 5681    |
| 2   | https://fr.wikipedia.org/wiki/Robot_de_cuisine                   | 200         | UTF-8    | 1161    |
| 3   | fr.wikipedia.org/wiki/Robot_d%27indexation                       | 301         |          | 1765    |
| 4   | https://fr.wikipedia.org/wiki/Bot_informatique                   | 200         | UTF-8    | 2583    |
| 5   | https://fr.wikipedia.org/wiki/Atlas_(robot)                      | 200         | UTF-8    | 1167    |
| 6   | https://roboty.magistry.fr                                       |             |          | 0       |
| 7   | https://fr.wikipedia.org/wiki/Robot_(Leonard_de_Vinci)           | 404         | UTF-8    | 440     |
| 8   | https://fr.wiktionary.org/wiki/robot                             | 200         | UTF-8    | 4813    |
| 9   | https://fr.wikipedia.org/wiki/Protocole_d%27exclusion_des_robots | 200         | UTF-8    | 1139    |
| 10  | https://fr.wikipedia.org/wiki/Robotique                          | 200         | UTF-8    | 13025   |
| N   | URL                                                              | Statut HTTP | Encodage | Nb mots |
| 1   | https://fr.wikipedia.org/wiki/Robot                              | 200         | UTF-8    | 5681    |
| 2   | https://fr.wikipedia.org/wiki/Robot_de_cuisine                   | 200         | UTF-8    | 1161    |
| 3   | fr.wikipedia.org/wiki/Robot_d%27indexation                       | 301         |          | 1765    |
| 4   | https://fr.wikipedia.org/wiki/Bot_informatique                   | 200         | UTF-8    | 2583    |
| 5   | https://fr.wikipedia.org/wiki/Atlas_(robot)                      | 200         | UTF-8    | 1167    |
| 6   | https://roboty.magistry.fr                                       |             |          | 0       |
| 7   | https://fr.wikipedia.org/wiki/Robot_(Leonard_de_Vinci)           | 404         | UTF-8    | 440     |
| 8   | https://fr.wiktionary.org/wiki/robot                             | 200         | UTF-8    | 4813    |
| 9   | https://fr.wikipedia.org/wiki/Protocole_d%27exclusion_des_robots | 200         | UTF-8    | 1139    |
| 10  | https://fr.wikipedia.org/wiki/Robotique                          | 200         | UTF-8    | 13025   |
Une solution simple possible : lorsque j'√©cris la premi√®re ligne, faire `echo .... > ${fichier}` au lieu de `>>` pour √©craser le fichier existant.
‚Üí √áa marche bien !

Ensuite pour le miniprojet 2 j'ai juste converti le tableau que je dressais en tsv en tableau html sur ce mod√®le : 
```html
<html>
<table>
 <tr><th>livre</th><th>taille</th></tr>
 <tr>
	<td>Du c√¥t√© de chez Swan</td><td>1.0Mo</td> 
 </tr>
 <tr>
	<td>L'assommoir</td><td>990 ko</td> 
 </tr>
</table>
</html>
```
En mettant en en-t√™te (balises `<th>`) les √©tiquettes des infos r√©cup√©r√©es.

---
## Wed 12.11.2025
### Correction miniprojet 3

Petit tip : on peut utiliser **F12** (ou inspecter) sur une phrase pour observer en vis-√†-vis le l'interpr√©tation du navigateur et le rendu final.

Moi j'avais tout mis sur une ligne quand j'utilisais echo (les balises les unes dans les autres sur une ligne), mais apparemment **on peut aussi mettre des retours √† la ligne dans la commande `echo`** : 

```bash
	echo -e "
		<tr>
			<td>${N}</td>
			<td>${line}</td>
			<td>${CODE_HTTP}</td>
			<td>${ENCODING}</td><td>${NB_MOTS}</td>
		</tr>" >> ${fichier}
```

- [x] tester le code remis en forme ‚úÖ 2025-11-12
- [ ] est-ce que les retours √† la ligne marchent dans une commande `echo` classique ou bien est-ce que l'option`-e` est n√©cessaire ?

J'ai essay√© d'ajouter une gestion des informations non-trouv√©es (pas de code http ‚Üí 000; pas d'encodage ‚Üí N/A) 
- [x] faire marcher ‚úÖ 2025-11-12
	- Le probl√®me √©tait que j'avais cr√©√© et utilis√© la variable `ENCODING` mais modifi√© la variable `encoding`. Attention √† la casse !!

Au final √ßa marche bien ! (code 000 et N/A pour l'encodage).
<figure>
	<img src="PJ/r√©sultat_tableau_html.png" />
	<figcaption>Tableau final</figcaption>
 </figure>

Autre question : 
- [x] pourquoi √©crire `exit 1` plut√¥t que `exit` ? ‚úÖ 2025-11-12
```bash
# V√©rification qu'on a donn√© un argument
if [ $# -ne 1 ] # teste si nb d'argument diff√©rent de 1
then
	echo "Donner un param√®tre (chemin vers fichier d'URLs)"
	exit 1 # fin de programme
fi
```
*Convention g√©n√©rale :* selon ce que renvoit le programme, on peut deviner comment s'est d√©roul√©e l'op√©ration.

| Code renvoy√© par le programme                                | Information donn√©e    |
| ------------------------------------------------------------ | --------------------- |
| 0                                                            | tout s'est bien pass√© |
| Tout autre nombre que 0<br>(convention sp√©cifique au script) | il y a eu une erreur  |

// Un peut comme les codes HTTP (200 = bon, sup√©rieur √† 200 : erreur qqpart)

Une petite curiosit√©... quand j'avais test√© mon code cette semaine, lancer le programme cr√©ait un tableau o√π UTF-8 n'√©tait pas toujours marqu√© de la m√™me fa√ßon (parfois en minuscules, parfois en majuscules). Pourtant, l√†, tout est en majuscules... bizarre.

### Git Pages
cf [[git-pages.pdf]].

On teste sur le [git-along](https://github.com/Tejante132/git-along) en mettant simplement la page index.html sur le menu racine notre d√©p√¥t. C'est un petit programme un peu bidon juste pour l'exemple.

Pour transformer en pages, on va sur la page de d√©p√¥t qui nous int√©resse, puis sur les param√®tres **de cette page**. Puis dans "Pages".

Choix √† faire : 

| Etape  | Choix                |
| ------ | -------------------- |
| Source | Deploy from a branch |
| Branch | main / root          |

Youhou ! ma premi√®re page GitHub : https://tejante132.github.io/git-along/ !!!
On peut aussi v√©rifier dans l'onglet "Action" ce qui est en train d'√™tre fait pour notre git. On voit au d√©but un logo orange qui indique que c'est en train de "charger" ? ‚Üí puis √ßa passe au voyant vert !

Pour trouver le nom de sa page web √† partir du nom du d√©p√¥t :
	le d√©p√¥t  ‚Üí https://github.com/Tejante132/git-along
	la page   ‚Üí https://tejante132.github.io/git-along/

Point sympa : le site est mis √† jour √† chaque push ! :D

### Finaliser le miniprojet (avec pages)

- [ ] Devoirs finition du miniprojet 3üîº üìÖ 2025-11-18
	- [x] Cr√©er une page d'accueil index.html qui utilise le *style Bulma* avec : ‚úÖ 2025-11-17
		- [x] une pr√©sentation rapide du mini-projet ‚úÖ 2025-11-12
		- [x] lien vers la page HTML qui contient le tableau de r√©sultat (genre "cliquer ici pour acc√©der au tableau" avec un `<a href="lien_vers_tableau">` I guess) ‚úÖ 2025-11-12
	- [x] *D√©ployer* (= push) une premi√®re fois la page pour v√©rifier que √ßa fonctionne ‚úÖ 2025-11-12
	- [ ] rajouter un peu de style [[CSS]] pour avoir une jolie page
		- [x] j'ai fait quelques trucs marrant ‚úÖ 2025-11-17
			- ex : rajout√© un lien vers plurital quand on clique sur le logo, fond, liens vers la liste d'URL et le tableau.
		- [x] aussi mettre joli tableau ‚úÖ 2025-11-17
			- [ ] d'abord faire √† la main une mise en page sympa du tableau depuis le fichier .html et noter les modifications effectu√©es 
			- [ ] puis l'int√©grer dans `miniprojet.sh`, i.e. mettre √† jour le script de fa√ßon √† g√©n√©rer directement la page avec le style Bulma qu'on lui a cr√©√©.
	- [ ] Cr√©er tag `miniprojet-3`.
D√©ployer (push) √† chaque √©tape pour voir la page mise √† jour, jusqu'√† avoir un r√©sultat fonctionnel.

cf [[style Bulma]], [[html-css.pdf]]

pages ouvertes pour reprendre la prochaine fois : 
- file:///home/clotilde/Documents/Obsidian%20Vault/Obsidian-Plurital/S7/PPE/PPE1-2025/index.html
- https://bulma.io/documentation/elements/image/
- [x] https://bulma.io/documentation/elements/table/ ‚úÖ 2025-11-17
- file:///home/clotilde/Documents/Obsidian%20Vault/Obsidian-Plurital/S7/PPE/PPE1-2526/exempliers/DemoBulma/3_index_bulma.html
- https://github.com/Tejante132/PPE1-2025
- https://github.com/Tejante132/PPE1-2025/tags

*Remarque sur les liens*: 
	Il semble que quand on utilise une balise `<a href="...">`, html (?) identifie tout seul si la source donn√©e semble √™tre un fichier "local" (ou page reli√©e, par exemple lien vers un autre fichier .html) ou un site web √† partir de la structure de la r√©f√©rence donn√©e.
	‚Üí Quand j'ai essay√© de faire un lien vers "plurital.org", √ßa essayait de me trouver un fichier local √©ponyme, jusqu'√† ce que je rajoute "https://" devant.

Mon 17.11.2025
**MVP**
Modifications effectu√©es sur tableau-fr.html pour styliser (coch√© = rajout√© dans `miniprojet.sh`) : 
- [ ] ajouter dans la balise d'ent√™te `<head>` le lien vers le style Bulma:
```html
	<link
	rel="stylesheet"
	href="https://cdn.jsdelivr.net/npm/bulma@1.0.2/css/versions/bulma-no-dark-mode.min.css">
```

- [ ] dans la balise ouvrante de la table, rajouter le style Bulma de table : 
```html
<table class="table">
```

- [ ] pr√©ciser en Bulma la ligne d'ent√™te en ajoutant une balise `<thead>` qui entoure la ligne d'ent√™te
```html
<thead>
	<tr><th>N</th>.....<tr>
</thead>
```
‚Üí dans le style que j'ai choisi, √ßa a juste rendu un peu plus √©pais le trait entre la premi√®re ligne et les suivantes.

= √©l√©ments minima pour les devoirs.

**Pour aller + loin (parce qu'on s'amuse bien en PPE)**
*Sur tableau (miniprojet.sh)*
Je regarde pour le *fun* si je peux ajouter quelques autres options sympas, par exemple essayer de faire en sorte que les pages aient le m√™me style (index et tableau).
- [ ] rajouter un style sp√©cial aux cases dans le cas o√π on n'a pas trouv√© une certaine info, ex
```html
		<tr>
			<td>https://roboty.magistry.fr</td>
			<td class="is-warning">000</td>
			<td class="is-warning">N/A</td>
			<td class="is-warning">0</td>
		</tr>
```
- [ ] rajouter √† chaque fois le lien vers le site, ex : 
```html
<tr><a href="https://roboty.magistry.fr">https://roboty.magistry.fr</a></tr>
```
- [ ] style qui met en valeur une ligne au survol ‚Üí `table is-hoverable`
- [ ] centrer la table ‚Üí pas encore trouv√©, mais √† d√©faut je peux mettre fullwidth et d√©finir une div centr√©e dans laquelle est mise la table : 
	- [ ] `table is-fullwitdh`
	- cf div utilis√©e dans index ‚Üì
- [ ] mettre m√™me fond √† tableau qu'√† index: rajouter les sections et divisions dans le body, autour de la table
Je rajoute au d√©but la m√™me ent√™te de page web que pour l'index : 
```html
<body>
	<section class="section has-background-black">
		<div class="container has-background-white">
			<table....
			.....
			</table>
		</div>
	</section>
</body>
```
J'ai choisi un fond noir pour aller avec le logo plurital sur la page d'index :) et puis √ßa va bien avec le jaune aussi.
Et je mets un petit titre √† la table (qui est, elle, dans sa propre division) : 
```html
			<section class="section column">
				<h3 class="title is-3 has-text-centered has-background-link-light">Informations sur les sites webs</h3>
			</section>
```
- [ ] faire en sorte que le "background" noir fasse la hauteur de la page
‚Üí attribut `is-fullheight` dans la section avec le fond noir.

*Sur index :* 
- J'ai mis le titre tout seul sur le fond gris / noir selon en blanc (`title has-text-white`) + le logo plurital
```html
<h1 class="title has-text-centered has-text-white">Informations sur les sites webs</h1>
<figure class="image">
		<a href="https://plurital.org"><img src="../PJ/plurital-logo.jpg" /></a>
</figure>
<br />
```
cf https://bulma.io/documentation/helpers/color-helpers/ 
- ajout√© des titres de sections avec fond, comme le prof
Il faut pr√©ciser dans la class title le num√©ro de titre. Plus on prend un num√©ro √©lev√©, plus la police est petite : 
```html
<h4 class="title is-4 has-background-link-light">C'est quoi le miniprojet de PPE ?</h2>
```

- [x] ajouter une image √† droite du texte (voir pour faire des colonnes), par exemple depuis l'URL https://cdn-blog.superprof.com/blog_fr/wp-content/uploads/2020/11/cours-informatique-programmation-973x649.jpg.webp , ou plut√¥t par exemple mettre le logo plurital √† droite ou gauche du titre *si la page est plus grande qu'une certaine largeur*. ‚Üí parce qu'en fait je regardais tout en moiti√© d'√©cran et j'aimais bien le rendu, mais en essayant de mettre en pleine page je trouve √ßa moche moche. ‚úÖ 2025-11-17
      https://bulma.io/documentation/columns/responsiveness/
```html
<div class="columns is-vcentered">
  <div class="column">1</div>
  <div class="column">2</div>
  <div class="column">3</div>
  <div class="column">4</div>
</div>
```
‚Üí ce qui est super c'est que **par d√©faut les colonnes ne s'affichent c√¥te √† c√¥t√© que pour tablette et + grand (tablette, desktop)**; elles s'affichent l'*une apr√®s l'autre* sur mobile (correspond aussi pour moi √† quand je r√©duit beaucoup la largeur de la fen√™tre) *sauf* si on rajoute `is-mobile` ([source](https://bulma.io/documentation/columns/responsiveness/)). A l'inverse, si je veux seulement les colonnes pour le desktop, je peux utiliser `is-desktop`. 
‚Üí je peux centrer verticalement le texte dans les colonnes avec `is-vcentered` ([source](https://stackoverflow.com/questions/44897794/how-to-vertically-center-elements-in-bulma)).
J'ai fait un encart de titre √† part avec titre et logo c√¥te √† c√¥te (√† utiliser aussi pour `miniprojet.sh` ‚Üí tableau)
```html
<!-- Encart titre et logo c√¥te √† c√¥te -->
<br />
<div class="columns is-vcentered">
	<div class="column">
		<figure class="image">
			<a href="https://plurital.org"><img src="PJ/plurital-logo.jpg" /></a>
		</figure>
	</div>
	<div class="column"><h1 class="title is-1 is-1-desktop is-2-tablet is-6-mobile has-text-centered has-text-white">Miniprojet de PPE</h1></div>
</div>
```
‚ö†Ô∏è pas le m√™me chemin relatif vers le logo selon la page (tableau ou index) comme pas plac√©s au m√™me endroit du projet.
- fa√ßon absolue de le faire ? ‚Üí le souci c'est que si je mets un chemin "absolu" √ßa place par rapport √† o√π la page est ouverte... pas l'air de marcher...


**Pour une autre fois si j'ai du temps, je trouverais cool de chercher comment :**
- [ ] hauteur de la page, ni plus ni moins (et que le reste soit scrollable)